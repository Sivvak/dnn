{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84VetyCaGLyR"
   },
   "source": [
    "<center><img src='https://drive.google.com/uc?id=1_utx_ZGclmCwNttSe40kYA6VHzNocdET' height=\"60\"></center>\n",
    "\n",
    "AI TECH - Akademia Innowacyjnych Zastosowań Technologii Cyfrowych. Program Operacyjny Polska Cyfrowa na lata 2014-2020\n",
    "\n",
    "<hr>\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1BXZ0u3562N_MqCLcekI-Ens77Kk4LpPm'></center>\n",
    "\n",
    "<center>\n",
    "Projekt współfinansowany ze środków Unii Europejskiej w ramach Europejskiego Funduszu Rozwoju Regionalnego \n",
    "Program Operacyjny Polska Cyfrowa na lata 2014-2020,\n",
    "Oś Priorytetowa nr 3 \"Cyfrowe kompetencje społeczeństwa\" Działanie  nr 3.2 \"Innowacyjne rozwiązania na rzecz aktywizacji cyfrowej\" \n",
    "Tytuł projektu:  „Akademia Innowacyjnych Zastosowań Technologii Cyfrowych (AI Tech)”\n",
    "    </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ziZ9i7tXbO1T"
   },
   "source": [
    "In this lab, you will implement some of the techniques discussed in the lecture.\n",
    "\n",
    "Below you are given a solution to the previous scenario. Note that it has two serious drawbacks:\n",
    "\n",
    "- The output predictions do not sum up to one (i.e. it does not return a distribution) even though the images always contain exactly one digit.\n",
    "- It uses MSE coupled with output sigmoid which can lead to saturation and slow convergence\n",
    "\n",
    "**Task 0.** Implement a numerically stable version of softmax.\n",
    "\n",
    "**Task 1.** Use softmax instead of coordinate-wise sigmoid and use log-loss instead of MSE. Test to see if this improves convergence. Hint: When implementing backprop it might be easier to consider these two functions as a single block and not even compute the gradient over the softmax values.\n",
    "\n",
    "**Task 2.** Implement L2 regularization and add momentum to the SGD algorithm. Play with different amounts of regularization and momentum. See if this improves accuracy/convergence.\n",
    "\n",
    "**Task 3 (optional).** Implement Adagrad or AdamW (currently popular in LLM training), dropout, and some simple data augmentations (e.g. tiny rotations/shifts, etc.). Again, test to see how these changes improve accuracy/convergence.\n",
    "\n",
    "**Task 4.** Try adding extra layers to the network. Again, test how the changes you introduced affect accuracy/convergence. As a start, you can try this architecture: [784,100,30,10]\n",
    "\n",
    "The provided model evaluation code (`evaluate_model`) may take some time to complete. During implementation, you can change the number of evaluated models to 1 and reduce the number of tested learning rates, and epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/pawel/repos/university/.venv/lib/python3.12/site-packages (4.66.6)\n",
      "Requirement already satisfied: pandas in /home/pawel/repos/university/.venv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/pawel/repos/university/.venv/lib/python3.12/site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/pawel/repos/university/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/pawel/repos/university/.venv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/pawel/repos/university/.venv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/pawel/repos/university/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "P22HqX9AbO1a"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from typing import List, Any, Tuple, Optional, Callable, Dict\n",
    "from numpy.typing import NDArray\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467,
     "referenced_widgets": [
      "0887eb284cde433a93dc63af32cc9d9b",
      "358d8edb5961494884a519823853bbc1",
      "7d1eed65ecca478498920df1c94a7ab1",
      "4cc42c27336c4004b8636f12fc602c83",
      "8e6fd5210a7348658773944836baa32d",
      "a411ff8732a84c4ca7c4619a848c773a",
      "f78d21be3caf4c00b6d38d6a9f41acd0",
      "3644dba634e84dbcba3cefcfe8491a05",
      "5410d60a73fb4378bfcde8a43a5f75f5",
      "5c9484a4d1b84db0aa4b37f215af9857",
      "05a12b77a0344f168b0ce86235411193",
      "3c475797b8c049bc900bdb82c9cee039",
      "0eb41ae3f7c344728e7610e0ac2e85a0",
      "5422f00593564627b8b1dbfe5c35375e",
      "1399a04e36fb44a0adb69561d892702b",
      "77df2c4f36ba43768f4b1afd46476f40",
      "b1ef11936cde4ac8ac4cb6fd24c75ede",
      "f676a65904b44a9baefab8c2a60e0eac",
      "6df1299ec9ef42098b23a7bd33291730",
      "36d9aac0f6324cc38e241ececa6a4983",
      "c34a23042e964b4395cc60915133b2ba",
      "fcda01da20f04bc0a9105f8b2baf9f2a",
      "179b581ba55d4666a7b598aa16d379c1",
      "d89d4753c54a4106853af165e3580381",
      "73d1c89e46e346978a24dfbdb3d107f9",
      "001c0f369ea04cdc87329ba70bc1da41",
      "6bc73c9a0f414c14ba1ba549122c6c9b",
      "937845c378944bcfba102e57219117fc",
      "a0ff7bcdb6f244d3945dea309ffdef09",
      "457f5c77ef924c8d939c36fbdb525c3c",
      "5ab3ead1b8ee4a62b0e732e88a4b612b",
      "6a6f8922ea26440ab907305b2f73c184",
      "3aded8ec6c8c435db31880259a9c1d6f",
      "7d6ec88d5f9b4b21b686f09fa415bd91",
      "2b08ddda39424469a3248b0f152b9248",
      "c5ef09e329c646ca98aebd21525f060e",
      "1b9c5bf3d8ae457a96d50baf49906929",
      "df3341a327524a1691aa7aca0006c490",
      "23a28a753e7c4234b064d55ba0d35eec",
      "e170ca7391a946b6a9febe117c16d87c",
      "93588a37aca74159889b81666166d80a",
      "12c9382de5be4afa97c32ad53880f443",
      "095b39beff514e799541c63dabc90507",
      "5a5c2ab34a0c4661b9c0611200e70e2b"
     ]
    },
    "executionInfo": {
     "elapsed": 1299,
     "status": "ok",
     "timestamp": 1635823776348,
     "user": {
      "displayName": "Marcin Mucha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghlkem9VmPW7wSPwLDYxT54wMMY6iF7Evvmx95duw=s64",
      "userId": "08004029552514744907"
     },
     "user_tz": -60
    },
    "id": "N9jGPaZhbO2B",
    "outputId": "aec94d43-a23e-474a-d748-e756ba658ca3"
   },
   "outputs": [],
   "source": [
    "# Let's read the mnist dataset\n",
    "\n",
    "\n",
    "def load_mnist(path: str = \".\"):\n",
    "    train_set = datasets.MNIST(path, train=True, download=True)\n",
    "    x_train = train_set.data.numpy()\n",
    "    _y_train = train_set.targets.numpy()\n",
    "\n",
    "    test_set = datasets.MNIST(path, train=False, download=True)\n",
    "    x_test = test_set.data.numpy()\n",
    "    _y_test = test_set.targets.numpy()\n",
    "\n",
    "    x_train = x_train.reshape((x_train.shape[0], 28 * 28)) / 255.0\n",
    "    x_test = x_test.reshape((x_test.shape[0], 28 * 28)) / 255.0\n",
    "\n",
    "    y_train = np.zeros((_y_train.shape[0], 10))\n",
    "    y_train[np.arange(_y_train.shape[0]), _y_train] = 1\n",
    "\n",
    "    y_test = np.zeros((_y_test.shape[0], 10))\n",
    "    y_test[np.arange(_y_test.shape[0]), _y_test] = 1\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "w3gAyqw4bO1p"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z: NDArray[float]):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "\n",
    "def sigmoid_prime(z: NDArray[float]):\n",
    "    # Derivative of the sigmoid\n",
    "    return sigmoid(z) * (1 - sigmoid(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm-Up\n",
    "\n",
    "Implement a numerically stable version of softmax.  \n",
    "In general, softmax is defined as  \n",
    "$$\\text{softmax}(x_1, x_2, \\ldots, x_n) = (\\frac{e^{x_1}}{\\sum_i{e^{x_i}}}, \\frac{e^{x_2}}{\\sum_i{e^{x_i}}}, \\ldots, \\frac{e^{x_n}}{\\sum_i{e^{x_i}}})$$  \n",
    "However, taking $e^{1000000}$ can result in NaN.  \n",
    "Can you implement softmax so that the highest power to which e will be risen will be at most $0$ and the predictions will be mathematically equivalent?\n",
    "\n",
    "Hint: <sub><sub><sub>sǝnlɐʌ llɐ ɯoɹɟ ʇᴉ ʇɔɐɹʇqns puɐ ᴉ‾x ʇsǝƃɹɐl ǝɥʇ ǝʞɐʇ</sub></sub></sub>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unstable_softmax(x: NDArray[float], axis: int = -1):\n",
    "    e = np.exp(x)\n",
    "    return e / np.sum(e, axis=axis, keepdims=True)\n",
    "\n",
    "\n",
    "def stable_softmax(x: NDArray[float], axis: int = -1):\n",
    "    ## TODO\n",
    "    ###{\n",
    "    e = np.exp(x - x.max(axis=axis, keepdims=True))\n",
    "    return e / np.sum(e, axis=axis, keepdims=True)\n",
    "    ###}\n",
    "\n",
    "\n",
    "### TESTS ###\n",
    "def test_one(\n",
    "    x: NDArray[float],\n",
    "    y: NDArray[float],\n",
    "    proc_fn: Callable[[NDArray[float]], NDArray[float]],\n",
    "):\n",
    "    r = stable_softmax(x)\n",
    "    assert r.shape == x.shape\n",
    "    r = proc_fn(r)\n",
    "    assert r.shape == y.shape\n",
    "    diff = np.mean(np.abs(r - y))\n",
    "    assert diff <= 1e-5, r\n",
    "\n",
    "\n",
    "x1 = np.random.rand(100, 32).astype(np.float64)\n",
    "test_one(x1, np.ones(100), lambda x: x.sum(-1))\n",
    "test_one(x1, unstable_softmax(x1), lambda x: x)\n",
    "\n",
    "\n",
    "x2 = np.ones((100, 32), dtype=np.float64) * 1e6\n",
    "test_one(x2, np.ones_like(x2) / x2.shape[-1], lambda x: x)\n",
    "### TESTS END ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FgEA2XRRbO2X",
    "outputId": "f1672e48-5e18-4ad2-aa13-98e4e07a5fdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.0693: 100%|██████████| 10/10 [00:05<00:00,  1.74it/s]\n",
      "Epoch: 9, Accuracy: 0.0918: 100%|██████████| 10/10 [00:05<00:00,  1.78it/s]\n",
      "Epoch: 9, Accuracy: 0.1399: 100%|██████████| 10/10 [00:05<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.1315: 100%|██████████| 10/10 [00:05<00:00,  1.78it/s]\n",
      "Epoch: 9, Accuracy: 0.1755: 100%|██████████| 10/10 [00:05<00:00,  1.74it/s]\n",
      "Epoch: 9, Accuracy: 0.2162: 100%|██████████| 10/10 [00:05<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.489: 100%|██████████| 10/10 [00:05<00:00,  1.77it/s]\n",
      "Epoch: 9, Accuracy: 0.5077: 100%|██████████| 10/10 [00:05<00:00,  1.74it/s]\n",
      "Epoch: 9, Accuracy: 0.6276: 100%|██████████| 10/10 [00:05<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.881: 100%|██████████| 10/10 [00:05<00:00,  1.74it/s]\n",
      "Epoch: 9, Accuracy: 0.8882: 100%|██████████| 10/10 [00:05<00:00,  1.82it/s]\n",
      "Epoch: 9, Accuracy: 0.8938: 100%|██████████| 10/10 [00:05<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.9349: 100%|██████████| 10/10 [00:05<00:00,  1.77it/s]\n",
      "Epoch: 9, Accuracy: 0.9311: 100%|██████████| 10/10 [00:05<00:00,  1.70it/s]\n",
      "Epoch: 9, Accuracy: 0.9355: 100%|██████████| 10/10 [00:05<00:00,  1.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>LR</th>\n",
       "      <th>ACC_STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Base</td>\n",
       "      <td>10.000</td>\n",
       "      <td>93.4% +- 0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Base</td>\n",
       "      <td>1.000</td>\n",
       "      <td>88.8% +- 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Base</td>\n",
       "      <td>0.100</td>\n",
       "      <td>54.1% +- 6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Base</td>\n",
       "      <td>0.010</td>\n",
       "      <td>17.4% +- 3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10.0% +- 2.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  MODEL      LR       ACC_STD\n",
       "4  Base  10.000  93.4% +- 0.2\n",
       "3  Base   1.000  88.8% +- 0.5\n",
       "2  Base   0.100  54.1% +- 6.1\n",
       "1  Base   0.010  17.4% +- 3.5\n",
       "0  Base   0.001  10.0% +- 2.9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Network(object):\n",
    "    def __init__(self, sizes: List[int]):\n",
    "        # initialize biases and weights with random normal distr.\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(x, y) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "\n",
    "    def feedforward(self, a: NDArray[float]) -> NDArray[float]:\n",
    "        # Run the network on a single case\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(a @ w + b)\n",
    "\n",
    "        return a\n",
    "\n",
    "    def update_mini_batch(\n",
    "        self, x_mini_batch: NDArray[float], y_mini_batch: NDArray[float], eta: float\n",
    "    ) -> None:\n",
    "        # Update network weights and biases by applying a single step\n",
    "        # of gradient descent using backpropagation to compute the gradient.\n",
    "        # The gradient is computed for a mini_batch.\n",
    "        # eta is the learning rate\n",
    "\n",
    "        nabla_b, nabla_w = self.backprop(x_mini_batch, y_mini_batch)\n",
    "\n",
    "        self.weights = [w - eta * nw for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b - eta * nb for b, nb in zip(self.biases, nabla_b)]\n",
    "\n",
    "    def backprop(\n",
    "        self, x: NDArray[float], y: NDArray[float]\n",
    "    ) -> Tuple[List[NDArray[float]], List[NDArray[float]]]:\n",
    "        # For a single input (x,y) return a tuple of lists.\n",
    "        # First contains gradients over biases, second over weights.\n",
    "\n",
    "        assert len(x.shape) == 2  # batch, features\n",
    "        assert len(y.shape) == 2  # batch, classes\n",
    "        assert x.shape[0] == y.shape[0]\n",
    "\n",
    "        # First initialize the list of gradient arrays\n",
    "        delta_nabla_b = []\n",
    "        delta_nabla_w = []\n",
    "\n",
    "        # Then go forward remembering each layer input and value\n",
    "        # before sigmoid activation\n",
    "        layer_input = []\n",
    "        before_act = []\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            layer_input.append(x)\n",
    "            x = x @ w + b\n",
    "            before_act.append(x)\n",
    "            x = sigmoid(x)\n",
    "\n",
    "        # Now go backward from the final cost applying backpropagation\n",
    "        diff = self.cost_derivative(output_activations=x, y=y)\n",
    "        for linp, bef_act, w, b in reversed(\n",
    "            list(zip(layer_input, before_act, self.weights, self.biases))\n",
    "        ):\n",
    "            diff = sigmoid_prime(bef_act) * diff\n",
    "            delta_nabla_w.append(linp.T @ diff)\n",
    "            delta_nabla_b.append(np.sum(diff, axis=0))\n",
    "            diff = diff @ w.T\n",
    "\n",
    "        delta_nabla_w = reversed(delta_nabla_w)\n",
    "        delta_nabla_b = reversed(delta_nabla_b)\n",
    "\n",
    "        # Check shapes\n",
    "        delta_nabla_b = list(delta_nabla_b)\n",
    "        delta_nabla_w = list(delta_nabla_w)\n",
    "        assert len(delta_nabla_b) == len(self.biases), (\n",
    "            len(delta_nabla_b),\n",
    "            len(self.biases),\n",
    "        )\n",
    "        assert len(delta_nabla_w) == len(self.weights), (\n",
    "            len(delta_nabla_w),\n",
    "            len(self.weights),\n",
    "        )\n",
    "        for lid in range(len(self.weights)):\n",
    "            assert delta_nabla_b[lid].shape == self.biases[lid].shape, (\n",
    "                delta_nabla_b[lid].shape,\n",
    "                self.biases[lid].shape,\n",
    "            )\n",
    "            assert delta_nabla_w[lid].shape == self.weights[lid].shape, (\n",
    "                delta_nabla_w[lid].shape,\n",
    "                self.weights[lid].shape,\n",
    "            )\n",
    "\n",
    "        return delta_nabla_b, delta_nabla_w\n",
    "\n",
    "    def evaluate(\n",
    "        self, x_test_data: NDArray[float], y_test_data: NDArray[float]\n",
    "    ) -> float:\n",
    "        # Count the number of correct answers for test_data\n",
    "        test_results = [\n",
    "            (\n",
    "                np.argmax(self.feedforward(x_test_data[i].reshape(1, 784)), axis=-1),\n",
    "                np.argmax(y_test_data[i], axis=-1),\n",
    "            )\n",
    "            for i in range(len(x_test_data))\n",
    "        ]\n",
    "        # return accuracy\n",
    "        return np.mean([int((x == y).item()) for (x, y) in test_results]).item()\n",
    "\n",
    "    def cost_derivative(\n",
    "        self, output_activations: NDArray[float], y: NDArray[float]\n",
    "    ) -> NDArray[float]:\n",
    "        assert output_activations.shape == y.shape, (output_activations.shape, y.shape)\n",
    "        return (output_activations - y) / len(y)  # moved here from update_mini_batch\n",
    "\n",
    "    def optimize(\n",
    "        self,\n",
    "        training_data: Tuple[NDArray[float], NDArray[float]],\n",
    "        epochs: int,\n",
    "        mini_batch_size: int,\n",
    "        eta: float,\n",
    "        test_data: Optional[Tuple[NDArray[float], NDArray[float]]] = None,\n",
    "    ) -> None:\n",
    "        x_train, y_train = training_data\n",
    "        if test_data:\n",
    "            x_test, y_test = test_data\n",
    "        epoch_bar = tqdm(range(epochs), desc=\"Epoch\")\n",
    "        for j in epoch_bar:\n",
    "            for i in range(x_train.shape[0] // mini_batch_size):\n",
    "                x_mini_batch = x_train[\n",
    "                    i * mini_batch_size : (i * mini_batch_size + mini_batch_size)\n",
    "                ]\n",
    "                y_mini_batch = y_train[\n",
    "                    i * mini_batch_size : (i * mini_batch_size + mini_batch_size)\n",
    "                ]\n",
    "                self.update_mini_batch(x_mini_batch, y_mini_batch, eta)\n",
    "            if test_data:\n",
    "                epoch_bar.set_description_str(\n",
    "                    \"Epoch: {0}, Accuracy: {1}\".format(j, self.evaluate(x_test, y_test))\n",
    "                )\n",
    "            else:\n",
    "                epoch_bar.set_description_str(\"Epoch: {0}\".format(j))\n",
    "\n",
    "        return self.evaluate(x_test, y_test)\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    model_name: str,\n",
    "    model_constructor: Callable[[List[int]], Network],\n",
    "    result_storage: Dict[str, List[Any]],\n",
    "    layers: List[int] = [784, 30, 10],\n",
    "):\n",
    "    # Remove logs from the previous evaluation of the same model\n",
    "    result_storage[\"MODEL\"] = [\n",
    "        m for m in result_storage.get(\"MODEL\", []) if m != model_name\n",
    "    ]\n",
    "    result_storage[\"LR\"] = [\n",
    "        lr\n",
    "        for m, lr in zip(result_storage.get(\"MODEL\", []), result_storage.get(\"LR\", []))\n",
    "        if m != model_name\n",
    "    ]\n",
    "    result_storage[\"ACC_STD\"] = [\n",
    "        acc_std\n",
    "        for m, acc_std in zip(\n",
    "            result_storage.get(\"MODEL\", []), result_storage.get(\"ACC_STD\", [])\n",
    "        )\n",
    "        if m != model_name\n",
    "    ]\n",
    "    result_storage[\"ACC\"] = [\n",
    "        acc\n",
    "        for m, acc in zip(\n",
    "            result_storage.get(\"MODEL\", []), result_storage.get(\"ACC\", [])\n",
    "        )\n",
    "        if m != model_name\n",
    "    ]\n",
    "\n",
    "    for lr in [0.001, 0.01, 0.1, 1.0, 10.0]:\n",
    "\n",
    "        print(f\"Checking with lr = {lr}\")\n",
    "        np.random.seed(42)\n",
    "        accuracy_list = []\n",
    "        for i in range(3):\n",
    "            network = model_constructor(layers)\n",
    "            accuracy = network.optimize(\n",
    "                (x_train, y_train),\n",
    "                epochs=10,\n",
    "                mini_batch_size=100,\n",
    "                eta=lr,\n",
    "                test_data=(x_test, y_test),\n",
    "            )\n",
    "            accuracy_list.append(accuracy)\n",
    "\n",
    "        result_storage[\"MODEL\"].append(model_name)\n",
    "        result_storage[\"LR\"].append(lr)\n",
    "        result_storage[\"ACC_STD\"].append(\n",
    "            f\"{np.mean(accuracy_list) * 100:2.1f}% +- {np.std(accuracy_list) * 100:.1f}\"\n",
    "        )\n",
    "\n",
    "        result_storage[\"ACC\"].append(np.mean(accuracy_list))\n",
    "\n",
    "    df = pd.DataFrame(result_storage).sort_values(\"ACC\", ascending=False)\n",
    "    df = df[[c for c in df.columns if c != \"ACC\"]]\n",
    "    return df\n",
    "\n",
    "\n",
    "RESULTS = {}\n",
    "evaluate_model(\n",
    "    model_name=\"Base\",\n",
    "    model_constructor=lambda x: Network(x),\n",
    "    result_storage=RESULTS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Use softmax instead of coordinate-wise sigmoid and use log-loss instead of MSE. Test to see if this improves convergence.  \n",
    "Hint: When implementing backprop it might be easier to consider these two functions as a single block and not even compute the gradient over the softmax values.  \n",
    "If you have problems, please see Appendix A.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.1574: 100%|██████████| 10/10 [00:06<00:00,  1.55it/s]\n",
      "Epoch: 9, Accuracy: 0.1934: 100%|██████████| 10/10 [00:06<00:00,  1.52it/s]\n",
      "Epoch: 9, Accuracy: 0.2256: 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.6627: 100%|██████████| 10/10 [00:06<00:00,  1.61it/s]\n",
      "Epoch: 9, Accuracy: 0.6577: 100%|██████████| 10/10 [00:06<00:00,  1.64it/s]\n",
      "Epoch: 9, Accuracy: 0.6885: 100%|██████████| 10/10 [00:06<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.8665: 100%|██████████| 10/10 [00:06<00:00,  1.53it/s]\n",
      "Epoch: 9, Accuracy: 0.8733: 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]\n",
      "Epoch: 9, Accuracy: 0.8743: 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.9346: 100%|██████████| 10/10 [00:06<00:00,  1.56it/s]\n",
      "Epoch: 9, Accuracy: 0.9286: 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]\n",
      "Epoch: 9, Accuracy: 0.9321: 100%|██████████| 10/10 [00:06<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.9411: 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]\n",
      "Epoch: 9, Accuracy: 0.9412: 100%|██████████| 10/10 [00:06<00:00,  1.53it/s]\n",
      "Epoch: 9, Accuracy: 0.9402: 100%|██████████| 10/10 [00:06<00:00,  1.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>LR</th>\n",
       "      <th>ACC_STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SoftMax</td>\n",
       "      <td>10.000</td>\n",
       "      <td>94.1% +- 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Base</td>\n",
       "      <td>10.000</td>\n",
       "      <td>93.4% +- 0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SoftMax</td>\n",
       "      <td>1.000</td>\n",
       "      <td>93.2% +- 0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Base</td>\n",
       "      <td>1.000</td>\n",
       "      <td>88.8% +- 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SoftMax</td>\n",
       "      <td>0.100</td>\n",
       "      <td>87.1% +- 0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SoftMax</td>\n",
       "      <td>0.010</td>\n",
       "      <td>67.0% +- 1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Base</td>\n",
       "      <td>0.100</td>\n",
       "      <td>54.1% +- 6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SoftMax</td>\n",
       "      <td>0.001</td>\n",
       "      <td>19.2% +- 2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Base</td>\n",
       "      <td>0.010</td>\n",
       "      <td>17.4% +- 3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10.0% +- 2.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MODEL      LR       ACC_STD\n",
       "9  SoftMax  10.000  94.1% +- 0.0\n",
       "4     Base  10.000  93.4% +- 0.2\n",
       "8  SoftMax   1.000  93.2% +- 0.2\n",
       "3     Base   1.000  88.8% +- 0.5\n",
       "7  SoftMax   0.100  87.1% +- 0.3\n",
       "6  SoftMax   0.010  67.0% +- 1.3\n",
       "2     Base   0.100  54.1% +- 6.1\n",
       "5  SoftMax   0.001  19.2% +- 2.8\n",
       "1     Base   0.010  17.4% +- 3.5\n",
       "0     Base   0.001  10.0% +- 2.9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Task1(Network):\n",
    "    def __init__(self, sizes: List[int]):\n",
    "        # initialize biases and weights with random normal distr.\n",
    "        super().__init__(sizes=sizes)\n",
    "\n",
    "    def feedforward(self, a: NDArray[float]) -> NDArray[float]:\n",
    "        # Run the network on a single case\n",
    "\n",
    "        ## TODO\n",
    "        ###{\n",
    "        for i, b, w in zip(np.arange(len(self.biases)), self.biases, self.weights):\n",
    "            a = (\n",
    "                stable_softmax(a @ w + b)\n",
    "                if i == len(self.biases) - 1\n",
    "                else sigmoid(a @ w + b)\n",
    "            )\n",
    "        ###}\n",
    "\n",
    "        return a\n",
    "\n",
    "    def backprop(\n",
    "        self, x: NDArray[float], y: NDArray[float]\n",
    "    ) -> Tuple[List[NDArray[float]], List[NDArray[float]]]:\n",
    "        # For a single input (x,y) return a tuple of lists.\n",
    "        # First contains gradients over biases, second over weights.\n",
    "\n",
    "        assert len(x.shape) == 2  # batch, features\n",
    "        assert len(y.shape) == 2  # batch, classes\n",
    "        assert x.shape[0] == y.shape[0]\n",
    "\n",
    "        ##TODO\n",
    "        ###{\n",
    "        # First initialize the list of gradient arrays\n",
    "        delta_nabla_b = []\n",
    "        delta_nabla_w = []\n",
    "\n",
    "        # Then go forward remembering each layer input and value\n",
    "        # before sigmoid activation\n",
    "        layer_input = []\n",
    "        before_act = []\n",
    "        for i, w, b in zip(np.arange(len(self.biases)), self.weights, self.biases):\n",
    "            layer_input.append(x)\n",
    "            x = x @ w + b\n",
    "            before_act.append(x)\n",
    "            x = stable_softmax(x) if i == len(self.biases) - 1 else sigmoid(x)\n",
    "\n",
    "        # Now go backward from the final cost applying backpropagation\n",
    "        diff = self.cost_derivative(output_activations=x, y=y)\n",
    "        for i, linp, bef_act, w, b in reversed(\n",
    "            list(\n",
    "                zip(\n",
    "                    np.arange(len(self.biases)),\n",
    "                    layer_input,\n",
    "                    before_act,\n",
    "                    self.weights,\n",
    "                    self.biases,\n",
    "                )\n",
    "            )\n",
    "        ):\n",
    "            if i != len(self.biases) - 1:\n",
    "                diff = sigmoid_prime(bef_act) * diff\n",
    "            delta_nabla_w.append(linp.T @ diff)\n",
    "            delta_nabla_b.append(np.sum(diff, axis=0))\n",
    "            diff = diff @ w.T\n",
    "\n",
    "        delta_nabla_w = reversed(delta_nabla_w)\n",
    "        delta_nabla_b = reversed(delta_nabla_b)\n",
    "        ###}\n",
    "\n",
    "        # Check shapes\n",
    "        delta_nabla_b = list(delta_nabla_b)\n",
    "        delta_nabla_w = list(delta_nabla_w)\n",
    "        assert len(delta_nabla_b) == len(self.biases), (\n",
    "            len(delta_nabla_b),\n",
    "            len(self.biases),\n",
    "        )\n",
    "        assert len(delta_nabla_w) == len(self.weights), (\n",
    "            len(delta_nabla_w),\n",
    "            len(self.weights),\n",
    "        )\n",
    "        for lid in range(len(self.weights)):\n",
    "            assert delta_nabla_b[lid].shape == self.biases[lid].shape, (\n",
    "                delta_nabla_b[lid].shape,\n",
    "                self.biases[lid].shape,\n",
    "            )\n",
    "            assert delta_nabla_w[lid].shape == self.weights[lid].shape, (\n",
    "                delta_nabla_w[lid].shape,\n",
    "                self.weights[lid].shape,\n",
    "            )\n",
    "\n",
    "        return delta_nabla_b, delta_nabla_w\n",
    "\n",
    "    def cost_derivative(\n",
    "        self, output_activations: NDArray[float], y: NDArray[float]\n",
    "    ) -> NDArray[float]:\n",
    "        assert output_activations.shape == y.shape, (output_activations.shape, y.shape)\n",
    "        ## TODO\n",
    "        ###{\n",
    "        return (output_activations - y) / len(y)  # moved here from update_mini_batch\n",
    "        ###}\n",
    "\n",
    "\n",
    "evaluate_model(\n",
    "    model_name=\"SoftMax\",\n",
    "    model_constructor=lambda x: Task1(x),\n",
    "    result_storage=RESULTS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Implement L2 regularization and add momentum to the SGD algorithm. Play with different amounts of regularization and momentum. See if this improves accuracy/convergence.  \n",
    "A few notes:\n",
    "\n",
    "- do not regularize the biases\n",
    "- you can see an example pseudocode here [pytorch.org/docs/stable/generated/torch.optim.SGD.html](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.1505: 100%|██████████| 10/10 [00:06<00:00,  1.65it/s]\n",
      "Epoch: 9, Accuracy: 0.1529: 100%|██████████| 10/10 [00:06<00:00,  1.66it/s]\n",
      "Epoch: 9, Accuracy: 0.1456: 100%|██████████| 10/10 [00:06<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.3513: 100%|██████████| 10/10 [00:05<00:00,  1.72it/s]\n",
      "Epoch: 9, Accuracy: 0.3134: 100%|██████████| 10/10 [00:05<00:00,  1.67it/s]\n",
      "Epoch: 9, Accuracy: 0.356: 100%|██████████| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.8669: 100%|██████████| 10/10 [00:06<00:00,  1.66it/s]\n",
      "Epoch: 9, Accuracy: 0.8537: 100%|██████████| 10/10 [00:05<00:00,  1.69it/s]\n",
      "Epoch: 9, Accuracy: 0.8663: 100%|██████████| 10/10 [00:06<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.9383: 100%|██████████| 10/10 [00:05<00:00,  1.73it/s]\n",
      "Epoch: 9, Accuracy: 0.9456: 100%|██████████| 10/10 [00:05<00:00,  1.80it/s]\n",
      "Epoch: 9, Accuracy: 0.9416: 100%|██████████| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.8798: 100%|██████████| 10/10 [00:06<00:00,  1.66it/s]\n",
      "Epoch: 9, Accuracy: 0.8698: 100%|██████████| 10/10 [00:05<00:00,  1.68it/s]\n",
      "Epoch: 9, Accuracy: 0.8771: 100%|██████████| 10/10 [00:05<00:00,  1.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>LR</th>\n",
       "      <th>ACC_STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>L2&amp;Momentum</td>\n",
       "      <td>1.000</td>\n",
       "      <td>94.2% +- 0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SoftMax</td>\n",
       "      <td>10.000</td>\n",
       "      <td>94.1% +- 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Base</td>\n",
       "      <td>10.000</td>\n",
       "      <td>93.4% +- 0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SoftMax</td>\n",
       "      <td>1.000</td>\n",
       "      <td>93.2% +- 0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Base</td>\n",
       "      <td>1.000</td>\n",
       "      <td>88.8% +- 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>L2&amp;Momentum</td>\n",
       "      <td>10.000</td>\n",
       "      <td>87.6% +- 0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SoftMax</td>\n",
       "      <td>0.100</td>\n",
       "      <td>87.1% +- 0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>L2&amp;Momentum</td>\n",
       "      <td>0.100</td>\n",
       "      <td>86.2% +- 0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SoftMax</td>\n",
       "      <td>0.010</td>\n",
       "      <td>67.0% +- 1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Base</td>\n",
       "      <td>0.100</td>\n",
       "      <td>54.1% +- 6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>L2&amp;Momentum</td>\n",
       "      <td>0.010</td>\n",
       "      <td>34.0% +- 1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SoftMax</td>\n",
       "      <td>0.001</td>\n",
       "      <td>19.2% +- 2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Base</td>\n",
       "      <td>0.010</td>\n",
       "      <td>17.4% +- 3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>L2&amp;Momentum</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15.0% +- 0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10.0% +- 2.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MODEL      LR       ACC_STD\n",
       "13  L2&Momentum   1.000  94.2% +- 0.3\n",
       "9       SoftMax  10.000  94.1% +- 0.0\n",
       "4          Base  10.000  93.4% +- 0.2\n",
       "8       SoftMax   1.000  93.2% +- 0.2\n",
       "3          Base   1.000  88.8% +- 0.5\n",
       "14  L2&Momentum  10.000  87.6% +- 0.4\n",
       "7       SoftMax   0.100  87.1% +- 0.3\n",
       "12  L2&Momentum   0.100  86.2% +- 0.6\n",
       "6       SoftMax   0.010  67.0% +- 1.3\n",
       "2          Base   0.100  54.1% +- 6.1\n",
       "11  L2&Momentum   0.010  34.0% +- 1.9\n",
       "5       SoftMax   0.001  19.2% +- 2.8\n",
       "1          Base   0.010  17.4% +- 3.5\n",
       "10  L2&Momentum   0.001  15.0% +- 0.3\n",
       "0          Base   0.001  10.0% +- 2.9"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Task2(Network):\n",
    "    def __init__(\n",
    "        self, sizes: List[int], l2_factor: float = 1e-4, momentum: float = 0.05\n",
    "    ):\n",
    "        # initialize biases and weights with random normal distr.\n",
    "        super().__init__(sizes=sizes)\n",
    "        self.l2_factor = l2_factor\n",
    "        self.momentum = momentum\n",
    "        ## TODO\n",
    "        ####{\n",
    "        self.biases = [np.random.randn(y) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(x, y) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        ###}\n",
    "\n",
    "    def update_mini_batch(\n",
    "        self, x_mini_batch: NDArray[float], y_mini_batch: NDArray[float], eta: float\n",
    "    ) -> None:\n",
    "        # Update network weights and biases by applying a single step\n",
    "        # of gradient descent (with momentum and l2 regularization) using backpropagation to compute the gradient.\n",
    "        # The gradient is computed for a mini_batch.\n",
    "        # eta is the learning rate\n",
    "        ## TODO\n",
    "        ###{\n",
    "        nabla_b, nabla_w = self.backprop(x_mini_batch, y_mini_batch)\n",
    "\n",
    "        # L2 regularization\n",
    "        if self.l2_factor != 0:\n",
    "            for i in range(len(nabla_w)):\n",
    "                nabla_w[i] += self.l2_factor * self.weights[i]\n",
    "\n",
    "        # momentum\n",
    "        if hasattr(self, \"acc_w_grad\") and hasattr(self, \"acc_b_grad\"):\n",
    "            self.acc_w_grad = [\n",
    "                acc * self.momentum + nabla\n",
    "                for acc, nabla in zip(self.acc_w_grad, nabla_w)\n",
    "            ]\n",
    "            self.acc_b_grad = [\n",
    "                acc * self.momentum + nabla\n",
    "                for acc, nabla in zip(self.acc_b_grad, nabla_b)\n",
    "            ]\n",
    "        else:\n",
    "            self.acc_w_grad = nabla_w\n",
    "            self.acc_b_grad = nabla_b\n",
    "\n",
    "        self.weights = [w - eta * nw for w, nw in zip(self.weights, self.acc_w_grad)]\n",
    "        self.biases = [b - eta * nb for b, nb in zip(self.biases, self.acc_b_grad)]\n",
    "        ###}\n",
    "\n",
    "\n",
    "evaluate_model(\n",
    "    model_name=\"L2&Momentum\",\n",
    "    model_constructor=lambda x: Task2(x, l2_factor=1e-4, momentum=0.8),\n",
    "    result_storage=RESULTS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 (optional)\n",
    "\n",
    "Implement Adagrad or AdamW (currently popular in LLM training), dropout, and some simple data augmentations (e.g. tiny rotations/shifts etc.). Again, test to see how these changes improve accuracy/convergence.  \n",
    "In case you want to learn about AdamW you can check the official [PyTorch docummentation](https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html) that contains pseudocode and the original paper [Decoupled Weight Decay Regularization](https://arxiv.org/abs/1711.05101).  \n",
    "In Appendix B you can find a simplified version of AdaGrad.  \n",
    "Below you can find brief information regarding the dropout:\n",
    "\n",
    "During the training phase, we want to make some activations $0$.\n",
    "It is usually implemented by zeroing each activation in the considered layer with probability $p$, and multiplying other activations by $\\frac{1}{1-p}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.9261: 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]\n",
      "Epoch: 9, Accuracy: 0.9247: 100%|██████████| 10/10 [00:06<00:00,  1.49it/s]\n",
      "Epoch: 9, Accuracy: 0.9219: 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.9556: 100%|██████████| 10/10 [00:06<00:00,  1.55it/s]\n",
      "Epoch: 9, Accuracy: 0.9555: 100%|██████████| 10/10 [00:06<00:00,  1.51it/s]\n",
      "Epoch: 9, Accuracy: 0.9566: 100%|██████████| 10/10 [00:06<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.9054: 100%|██████████| 10/10 [00:06<00:00,  1.47it/s]\n",
      "Epoch: 9, Accuracy: 0.9153: 100%|██████████| 10/10 [00:06<00:00,  1.46it/s]\n",
      "Epoch: 9, Accuracy: 0.9211: 100%|██████████| 10/10 [00:06<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]/tmp/ipykernel_13149/3286057103.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1.0 + np.exp(-z))\n",
      "Epoch: 9, Accuracy: 0.374: 100%|██████████| 10/10 [00:06<00:00,  1.45it/s]\n",
      "Epoch: 9, Accuracy: 0.603: 100%|██████████| 10/10 [00:06<00:00,  1.53it/s]\n",
      "Epoch: 9, Accuracy: 0.5703: 100%|██████████| 10/10 [00:06<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.1533: 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]\n",
      "Epoch: 9, Accuracy: 0.098: 100%|██████████| 10/10 [00:07<00:00,  1.39it/s]\n",
      "Epoch: 9, Accuracy: 0.0924: 100%|██████████| 10/10 [00:07<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.9241: 100%|██████████| 10/10 [00:14<00:00,  1.41s/it]\n",
      "Epoch: 9, Accuracy: 0.921: 100%|██████████| 10/10 [00:13<00:00,  1.34s/it]\n",
      "Epoch: 9, Accuracy: 0.9215: 100%|██████████| 10/10 [00:14<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.9548: 100%|██████████| 10/10 [00:13<00:00,  1.32s/it]\n",
      "Epoch: 9, Accuracy: 0.9522: 100%|██████████| 10/10 [00:14<00:00,  1.46s/it]\n",
      "Epoch: 9, Accuracy: 0.9527: 100%|██████████| 10/10 [00:14<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.9056: 100%|██████████| 10/10 [00:14<00:00,  1.43s/it]\n",
      "Epoch: 9, Accuracy: 0.8992: 100%|██████████| 10/10 [00:14<00:00,  1.45s/it]\n",
      "Epoch: 9, Accuracy: 0.9171: 100%|██████████| 10/10 [00:14<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]/tmp/ipykernel_13149/3286057103.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1.0 + np.exp(-z))\n",
      "Epoch: 9, Accuracy: 0.5686: 100%|██████████| 10/10 [00:14<00:00,  1.40s/it]\n",
      "Epoch: 9, Accuracy: 0.5438: 100%|██████████| 10/10 [00:13<00:00,  1.38s/it]\n",
      "Epoch: 9, Accuracy: 0.4649: 100%|██████████| 10/10 [00:13<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.1067: 100%|██████████| 10/10 [00:14<00:00,  1.47s/it]\n",
      "Epoch: 9, Accuracy: 0.1011: 100%|██████████| 10/10 [00:14<00:00,  1.41s/it]\n",
      "Epoch: 9, Accuracy: 0.098: 100%|██████████| 10/10 [00:14<00:00,  1.47s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>LR</th>\n",
       "      <th>ACC_STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Optimizer</td>\n",
       "      <td>0.010</td>\n",
       "      <td>95.6% +- 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Optimizer + dropout</td>\n",
       "      <td>0.010</td>\n",
       "      <td>95.3% +- 0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>L2&amp;Momentum</td>\n",
       "      <td>1.000</td>\n",
       "      <td>94.2% +- 0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SoftMax</td>\n",
       "      <td>10.000</td>\n",
       "      <td>94.1% +- 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Base</td>\n",
       "      <td>10.000</td>\n",
       "      <td>93.4% +- 0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SoftMax</td>\n",
       "      <td>1.000</td>\n",
       "      <td>93.2% +- 0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Optimizer</td>\n",
       "      <td>0.001</td>\n",
       "      <td>92.4% +- 0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Optimizer + dropout</td>\n",
       "      <td>0.001</td>\n",
       "      <td>92.2% +- 0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Optimizer</td>\n",
       "      <td>0.100</td>\n",
       "      <td>91.4% +- 0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Optimizer + dropout</td>\n",
       "      <td>0.100</td>\n",
       "      <td>90.7% +- 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Base</td>\n",
       "      <td>1.000</td>\n",
       "      <td>88.8% +- 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>L2&amp;Momentum</td>\n",
       "      <td>10.000</td>\n",
       "      <td>87.6% +- 0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SoftMax</td>\n",
       "      <td>0.100</td>\n",
       "      <td>87.1% +- 0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>L2&amp;Momentum</td>\n",
       "      <td>0.100</td>\n",
       "      <td>86.2% +- 0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SoftMax</td>\n",
       "      <td>0.010</td>\n",
       "      <td>67.0% +- 1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Base</td>\n",
       "      <td>0.100</td>\n",
       "      <td>54.1% +- 6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Optimizer + dropout</td>\n",
       "      <td>1.000</td>\n",
       "      <td>52.6% +- 4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Optimizer</td>\n",
       "      <td>1.000</td>\n",
       "      <td>51.6% +- 10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>L2&amp;Momentum</td>\n",
       "      <td>0.010</td>\n",
       "      <td>34.0% +- 1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SoftMax</td>\n",
       "      <td>0.001</td>\n",
       "      <td>19.2% +- 2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Base</td>\n",
       "      <td>0.010</td>\n",
       "      <td>17.4% +- 3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>L2&amp;Momentum</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15.0% +- 0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Optimizer</td>\n",
       "      <td>10.000</td>\n",
       "      <td>11.5% +- 2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Optimizer + dropout</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.2% +- 0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10.0% +- 2.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MODEL      LR        ACC_STD\n",
       "16            Optimizer   0.010   95.6% +- 0.0\n",
       "21  Optimizer + dropout   0.010   95.3% +- 0.1\n",
       "13          L2&Momentum   1.000   94.2% +- 0.3\n",
       "9               SoftMax  10.000   94.1% +- 0.0\n",
       "4                  Base  10.000   93.4% +- 0.2\n",
       "8               SoftMax   1.000   93.2% +- 0.2\n",
       "15            Optimizer   0.001   92.4% +- 0.2\n",
       "20  Optimizer + dropout   0.001   92.2% +- 0.1\n",
       "17            Optimizer   0.100   91.4% +- 0.6\n",
       "22  Optimizer + dropout   0.100   90.7% +- 0.7\n",
       "3                  Base   1.000   88.8% +- 0.5\n",
       "14          L2&Momentum  10.000   87.6% +- 0.4\n",
       "7               SoftMax   0.100   87.1% +- 0.3\n",
       "12          L2&Momentum   0.100   86.2% +- 0.6\n",
       "6               SoftMax   0.010   67.0% +- 1.3\n",
       "2                  Base   0.100   54.1% +- 6.1\n",
       "23  Optimizer + dropout   1.000   52.6% +- 4.4\n",
       "18            Optimizer   1.000  51.6% +- 10.1\n",
       "11          L2&Momentum   0.010   34.0% +- 1.9\n",
       "5               SoftMax   0.001   19.2% +- 2.8\n",
       "1                  Base   0.010   17.4% +- 3.5\n",
       "10          L2&Momentum   0.001   15.0% +- 0.3\n",
       "19            Optimizer  10.000   11.5% +- 2.7\n",
       "24  Optimizer + dropout  10.000   10.2% +- 0.4\n",
       "0                  Base   0.001   10.0% +- 2.9"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Task3Optimizer(Network):\n",
    "    def __init__(\n",
    "        self,\n",
    "        sizes: List[int],\n",
    "        weight_decay: float = 0.01,\n",
    "        beta_1: float = 0.9,\n",
    "        beta_2: float = 0.95,\n",
    "        dropout_p: float = 0.1,\n",
    "        eps=1e-5,\n",
    "    ):\n",
    "        # initialize biases and weights with random normal distr.\n",
    "        super().__init__(sizes=sizes)\n",
    "        self.weight_decay = weight_decay\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.dropout_p = dropout_p\n",
    "        self.eps = eps\n",
    "        ## TODO\n",
    "        ####{\n",
    "        self.biases = [np.random.randn(y) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(x, y) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "\n",
    "        self.momentum_1 = [np.zeros_like(w) for w in self.weights]\n",
    "        self.momentum_2 = [np.zeros_like(w) for w in self.weights]\n",
    "\n",
    "        self.momentum_1_div = self.beta_1\n",
    "        self.momentum_2_div = self.beta_2\n",
    "        ###}\n",
    "\n",
    "    def update_mini_batch(\n",
    "        self, x_mini_batch: NDArray[float], y_mini_batch: NDArray[float], eta: float\n",
    "    ) -> None:\n",
    "        # Update network weights and biases by applying a single step\n",
    "        # of gradient descent (with momentum and weight decay) using backpropagation to compute the gradient.\n",
    "        # The gradient is computed for a mini_batch.\n",
    "        # eta is the learning rate\n",
    "        ## TODO\n",
    "        ###{\n",
    "        nabla_b, nabla_w = self.backprop(x_mini_batch, y_mini_batch)\n",
    "\n",
    "        # weight decay\n",
    "        if self.weight_decay != 0:\n",
    "            self.weights = [w * (1 - self.weight_decay * eta) for w in self.weights]\n",
    "\n",
    "        # momentum\n",
    "        self.momentum_1 = [\n",
    "            (self.beta_1 * m + (1 - self.beta_1) * nw) / (1 - self.momentum_1_div)\n",
    "            for m, nw in zip(self.momentum_1, nabla_w)\n",
    "        ]\n",
    "        self.momentum_2 = [\n",
    "            (self.beta_2 * v + (1 - self.beta_2) * nw**2) / (1 - self.momentum_2_div)\n",
    "            for v, nw in zip(self.momentum_2, nabla_w)\n",
    "        ]\n",
    "\n",
    "        self.momentum_1_div *= self.momentum_1_div\n",
    "        self.momentum_2_div *= self.momentum_2_div\n",
    "\n",
    "        self.weights = [\n",
    "            w - eta * m1 / (np.sqrt(m2) + self.eps)\n",
    "            for w, m1, m2 in zip(self.weights, self.momentum_1, self.momentum_2)\n",
    "        ]\n",
    "        self.biases = [b - eta * nb for b, nb in zip(self.biases, nabla_b)]\n",
    "        ###}\n",
    "\n",
    "    def backprop(\n",
    "        self, x: NDArray[float], y: NDArray[float]\n",
    "    ) -> Tuple[List[NDArray[float]], List[NDArray[float]]]:\n",
    "        # For a single input (x,y) return a tuple of lists.\n",
    "        # First contains gradients over biases, second over weights.\n",
    "\n",
    "        assert len(x.shape) == 2  # batch, features\n",
    "        assert len(y.shape) == 2  # batch, classes\n",
    "        assert x.shape[0] == y.shape[0]\n",
    "\n",
    "        ##TODO\n",
    "        ###{\n",
    "        # First initialize the list of gradient arrays\n",
    "        delta_nabla_b = []\n",
    "        delta_nabla_w = []\n",
    "\n",
    "        # Then go forward remembering each layer input and value\n",
    "        # before sigmoid activation\n",
    "        layer_input = []\n",
    "        before_act = []\n",
    "        for i, w, b in zip(np.arange(len(self.biases)), self.weights, self.biases):\n",
    "            # implement dropout\n",
    "            if self.dropout_p != 0.0:\n",
    "                x = (\n",
    "                    x\n",
    "                    * (np.random.rand(x.shape[0], x.shape[1]) > self.dropout_p)\n",
    "                    / (1 - self.dropout_p)\n",
    "                )\n",
    "\n",
    "            layer_input.append(x)\n",
    "            x = x @ w + b\n",
    "            before_act.append(x)\n",
    "            x = stable_softmax(x) if i == len(self.biases) - 1 else sigmoid(x)\n",
    "\n",
    "        # Now go backward from the final cost applying backpropagation\n",
    "        diff = self.cost_derivative(output_activations=x, y=y)\n",
    "        for i, linp, bef_act, w, b in reversed(\n",
    "            list(\n",
    "                zip(\n",
    "                    np.arange(len(self.biases)),\n",
    "                    layer_input,\n",
    "                    before_act,\n",
    "                    self.weights,\n",
    "                    self.biases,\n",
    "                )\n",
    "            )\n",
    "        ):\n",
    "            if i != len(self.biases) - 1:\n",
    "                diff = sigmoid_prime(bef_act) * diff\n",
    "            delta_nabla_w.append(linp.T @ diff)\n",
    "            delta_nabla_b.append(np.sum(diff, axis=0))\n",
    "            diff = diff @ w.T\n",
    "\n",
    "        delta_nabla_w = reversed(delta_nabla_w)\n",
    "        delta_nabla_b = reversed(delta_nabla_b)\n",
    "        ###}\n",
    "\n",
    "        # Check shapes\n",
    "        delta_nabla_b = list(delta_nabla_b)\n",
    "        delta_nabla_w = list(delta_nabla_w)\n",
    "        assert len(delta_nabla_b) == len(self.biases), (\n",
    "            len(delta_nabla_b),\n",
    "            len(self.biases),\n",
    "        )\n",
    "        assert len(delta_nabla_w) == len(self.weights), (\n",
    "            len(delta_nabla_w),\n",
    "            len(self.weights),\n",
    "        )\n",
    "        for lid in range(len(self.weights)):\n",
    "            assert delta_nabla_b[lid].shape == self.biases[lid].shape, (\n",
    "                delta_nabla_b[lid].shape,\n",
    "                self.biases[lid].shape,\n",
    "            )\n",
    "            assert delta_nabla_w[lid].shape == self.weights[lid].shape, (\n",
    "                delta_nabla_w[lid].shape,\n",
    "                self.weights[lid].shape,\n",
    "            )\n",
    "\n",
    "        return delta_nabla_b, delta_nabla_w\n",
    "\n",
    "\n",
    "evaluate_model(\n",
    "    model_name=\"Optimizer\",\n",
    "    model_constructor=lambda x: Task3Optimizer(x, dropout_p=0.0),\n",
    "    result_storage=RESULTS,\n",
    ")\n",
    "\n",
    "evaluate_model(\n",
    "    model_name=\"Optimizer + dropout\",\n",
    "    model_constructor=lambda x: Task3Optimizer(x),\n",
    "    result_storage=RESULTS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place for remaining parts of task 3\n",
    "\n",
    "# here augmentations should be created ^^'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "Try adding extra layers to the network. Again, test how the changes you introduced affect accuracy/convergence. As a start, you can try this architecture: [784,100,30,10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.9429: 100%|██████████| 10/10 [00:28<00:00,  2.83s/it]\n",
      "Epoch: 9, Accuracy: 0.9402: 100%|██████████| 10/10 [00:25<00:00,  2.59s/it]\n",
      "Epoch: 9, Accuracy: 0.9433: 100%|██████████| 10/10 [00:30<00:00,  3.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.9631: 100%|██████████| 10/10 [00:28<00:00,  2.81s/it]\n",
      "Epoch: 9, Accuracy: 0.9606: 100%|██████████| 10/10 [00:26<00:00,  2.67s/it]\n",
      "Epoch: 9, Accuracy: 0.9556: 100%|██████████| 10/10 [00:26<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.9035: 100%|██████████| 10/10 [00:28<00:00,  2.85s/it]\n",
      "Epoch: 9, Accuracy: 0.8897: 100%|██████████| 10/10 [00:29<00:00,  2.93s/it]\n",
      "Epoch: 9, Accuracy: 0.8895: 100%|██████████| 10/10 [00:35<00:00,  3.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]/tmp/ipykernel_13149/3286057103.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1.0 + np.exp(-z))\n",
      "Epoch: 9, Accuracy: 0.0974: 100%|██████████| 10/10 [00:36<00:00,  3.60s/it]\n",
      "Epoch: 9, Accuracy: 0.101: 100%|██████████| 10/10 [00:36<00:00,  3.67s/it]\n",
      "Epoch: 9, Accuracy: 0.0974: 100%|██████████| 10/10 [00:35<00:00,  3.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking with lr = 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Accuracy: 0.098: 100%|██████████| 10/10 [00:37<00:00,  3.77s/it]\n",
      "Epoch: 9, Accuracy: 0.1135: 100%|██████████| 10/10 [00:37<00:00,  3.72s/it]\n",
      "Epoch: 9, Accuracy: 0.0892: 100%|██████████| 10/10 [00:26<00:00,  2.69s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>LR</th>\n",
       "      <th>ACC_STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Optimizer (extra layers)</td>\n",
       "      <td>0.010</td>\n",
       "      <td>96.0% +- 0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Optimizer</td>\n",
       "      <td>0.010</td>\n",
       "      <td>95.6% +- 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Optimizer + dropout</td>\n",
       "      <td>0.010</td>\n",
       "      <td>95.3% +- 0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Optimizer (extra layers)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>94.2% +- 0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>L2&amp;Momentum</td>\n",
       "      <td>1.000</td>\n",
       "      <td>94.2% +- 0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SoftMax</td>\n",
       "      <td>10.000</td>\n",
       "      <td>94.1% +- 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Base</td>\n",
       "      <td>10.000</td>\n",
       "      <td>93.4% +- 0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SoftMax</td>\n",
       "      <td>1.000</td>\n",
       "      <td>93.2% +- 0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Optimizer</td>\n",
       "      <td>0.001</td>\n",
       "      <td>92.4% +- 0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Optimizer + dropout</td>\n",
       "      <td>0.001</td>\n",
       "      <td>92.2% +- 0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Optimizer</td>\n",
       "      <td>0.100</td>\n",
       "      <td>91.4% +- 0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Optimizer + dropout</td>\n",
       "      <td>0.100</td>\n",
       "      <td>90.7% +- 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Optimizer (extra layers)</td>\n",
       "      <td>0.100</td>\n",
       "      <td>89.4% +- 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Base</td>\n",
       "      <td>1.000</td>\n",
       "      <td>88.8% +- 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>L2&amp;Momentum</td>\n",
       "      <td>10.000</td>\n",
       "      <td>87.6% +- 0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SoftMax</td>\n",
       "      <td>0.100</td>\n",
       "      <td>87.1% +- 0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>L2&amp;Momentum</td>\n",
       "      <td>0.100</td>\n",
       "      <td>86.2% +- 0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SoftMax</td>\n",
       "      <td>0.010</td>\n",
       "      <td>67.0% +- 1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Base</td>\n",
       "      <td>0.100</td>\n",
       "      <td>54.1% +- 6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Optimizer + dropout</td>\n",
       "      <td>1.000</td>\n",
       "      <td>52.6% +- 4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Optimizer</td>\n",
       "      <td>1.000</td>\n",
       "      <td>51.6% +- 10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>L2&amp;Momentum</td>\n",
       "      <td>0.010</td>\n",
       "      <td>34.0% +- 1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SoftMax</td>\n",
       "      <td>0.001</td>\n",
       "      <td>19.2% +- 2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Base</td>\n",
       "      <td>0.010</td>\n",
       "      <td>17.4% +- 3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>L2&amp;Momentum</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15.0% +- 0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Optimizer</td>\n",
       "      <td>10.000</td>\n",
       "      <td>11.5% +- 2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Optimizer + dropout</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.2% +- 0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10.0% +- 2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Optimizer (extra layers)</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.0% +- 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Optimizer (extra layers)</td>\n",
       "      <td>1.000</td>\n",
       "      <td>9.9% +- 0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       MODEL      LR        ACC_STD\n",
       "26  Optimizer (extra layers)   0.010   96.0% +- 0.3\n",
       "16                 Optimizer   0.010   95.6% +- 0.0\n",
       "21       Optimizer + dropout   0.010   95.3% +- 0.1\n",
       "25  Optimizer (extra layers)   0.001   94.2% +- 0.1\n",
       "13               L2&Momentum   1.000   94.2% +- 0.3\n",
       "9                    SoftMax  10.000   94.1% +- 0.0\n",
       "4                       Base  10.000   93.4% +- 0.2\n",
       "8                    SoftMax   1.000   93.2% +- 0.2\n",
       "15                 Optimizer   0.001   92.4% +- 0.2\n",
       "20       Optimizer + dropout   0.001   92.2% +- 0.1\n",
       "17                 Optimizer   0.100   91.4% +- 0.6\n",
       "22       Optimizer + dropout   0.100   90.7% +- 0.7\n",
       "27  Optimizer (extra layers)   0.100   89.4% +- 0.7\n",
       "3                       Base   1.000   88.8% +- 0.5\n",
       "14               L2&Momentum  10.000   87.6% +- 0.4\n",
       "7                    SoftMax   0.100   87.1% +- 0.3\n",
       "12               L2&Momentum   0.100   86.2% +- 0.6\n",
       "6                    SoftMax   0.010   67.0% +- 1.3\n",
       "2                       Base   0.100   54.1% +- 6.1\n",
       "23       Optimizer + dropout   1.000   52.6% +- 4.4\n",
       "18                 Optimizer   1.000  51.6% +- 10.1\n",
       "11               L2&Momentum   0.010   34.0% +- 1.9\n",
       "5                    SoftMax   0.001   19.2% +- 2.8\n",
       "1                       Base   0.010   17.4% +- 3.5\n",
       "10               L2&Momentum   0.001   15.0% +- 0.3\n",
       "19                 Optimizer  10.000   11.5% +- 2.7\n",
       "24       Optimizer + dropout  10.000   10.2% +- 0.4\n",
       "0                       Base   0.001   10.0% +- 2.9\n",
       "29  Optimizer (extra layers)  10.000   10.0% +- 1.0\n",
       "28  Optimizer (extra layers)   1.000    9.9% +- 0.2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TODO\n",
    "evaluate_model(\n",
    "    model_name=\"Optimizer (extra layers)\",\n",
    "    model_constructor=lambda x: Task3Optimizer(x, dropout_p=0.0),\n",
    "    result_storage=RESULTS,\n",
    "    layers=[784, 100, 30, 10],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix A - Log-loss and softmax\n",
    "\n",
    "Let's compute the following derivative\n",
    "$$\\frac{\\partial\\left(\\sum_{i}{y_{b, i}\\log{(\\text{prediction}_{b, i}})}\\right)}{\\partial z_{b, f}}$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "y_{b, i} = \\begin{cases}\n",
    "1 & \\text{if $b$'th image belongs to $i$'th class}\\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "To do so we can use the chain rule:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f(g(x))}{\\partial x} = \\frac{\\partial f(g(x))}{\\partial g(x)}  \\frac{\\partial g(x)}{\\partial x}\n",
    "$$\n",
    "\n",
    "the rule for the sum\n",
    "\n",
    "$$\n",
    "\\frac{\\partial (f(x) + g(x))}{\\partial x} = \\frac{\\partial f(x)}{\\partial x} +   \\frac{\\partial g(x)}{\\partial x}\n",
    "$$\n",
    "\n",
    "and the fact that the derivative of natural logarithm is\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\log(x)}{\\partial x} = \\frac{1}{x}\n",
    "$$\n",
    "\n",
    "Using those rules we can observe that indeed:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial  \\left(\\sum_{i}{y_{b, i}\\log{(\\text{prediction}_{b, i}})}\\right)}{\\partial z_{b, f}} = \\sum_{i}{y_{b,i} \\frac{1}{\\text{prediction}_{b, i}} \\frac{ \\partial \\text{prediction}_{b, i}}{\\partial z_{b, f}}}\n",
    "$$\n",
    "\n",
    "Let us review the multiplication rule:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial (f(x)g(x))}{\\partial x} = \\frac{\\partial f(x)}{\\partial x}g(x)  + f(x)\\frac{\\partial g(x)}{\\partial x}\n",
    "$$\n",
    "\n",
    "and that\n",
    "\n",
    "$$\n",
    "\\frac{\\partial e^x}{\\partial x} = e^x\n",
    "$$\n",
    "\n",
    "From the definition:\n",
    "\n",
    "$$\n",
    "\\text{prediction}_{b, f} = \\frac{e^{z_{b, f}}}{\\sum_{i}{e^{z_{b, i}}}}\n",
    "$$\n",
    "\n",
    "We can observe that for $k \\not= f$\n",
    "\n",
    "$$\n",
    "\\frac{ \\partial \\text{prediction}_{b, k}}{\\partial z_{b, f}}\n",
    "= 0 - \\frac{e^{z_{k, b}} e^{z_{b, f}} }{\\left(\\sum_{i}{e^{z_{b, i}}}\\right)^2}\n",
    "$$\n",
    "\n",
    "and that\n",
    "\n",
    "$$\n",
    "\\frac{ \\partial \\text{prediction}_{b, f}}{\\partial z_{b, f}}\n",
    "= \\frac{e^{z_{b, f}}}{\\sum_{i}{e^{z_{b, i}}}} - \\left(\\frac{e^{z_{b, f}}}{\\sum_{i}{e^{z_{b, i}}}}\\right)^2\n",
    "$$\n",
    "\n",
    "Therefore\n",
    "\n",
    "$$\n",
    "y_{b,i} \\frac{1}{\\text{prediction}_{b, i}} \\frac{ \\partial \\text{prediction}_{b, i}}{\\partial z_{b, f}} = \\begin{cases}\n",
    "y_{b,i}\\left(-\\frac{e^{z_{b, f}}}{\\sum_{i}{e^{z_{b, i}}}}\\right) & \\text{if } i \\not= f\\\\\n",
    "y_{b,i}\\left(1 - \\frac{e^{z_{b, f}}}{\\sum_{i}{e^{z_{b, i}}}}\\right) & \\text{if } i = f\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "in other words\n",
    "\n",
    "$$\n",
    "y_{b,i} \\frac{1}{\\text{prediction}_{b, i}} \\frac{ \\partial \\text{prediction}_{b, i}}{\\partial z_{b, f}} = \\begin{cases}\n",
    "y_{b,i}\\left(-\\text{prediction}_{b, f}\\right) & \\text{if } i \\not= f\\\\\n",
    "y_{b,i}\\left(1 - \\text{prediction}_{b, f}\\right) & \\text{if } i = f\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "As we just sum over $i$, and for each $b$ there is exactly one $i$ such that $y_{b, i} = 1$ and for $j \\not= i$ $y_{b, j} = 0$, therefore in the end we have that\n",
    "\n",
    "$$\n",
    "\\frac{\\partial  \\left(\\sum_{i}{y_{b, i}\\log{(\\text{prediction}_{b, i}})}\\right)}{\\partial z_{b, f}} = y_{b, f} - \\text{prediction}_{b, f}\n",
    "$$\n",
    "\n",
    "what can be written as:\n",
    "\n",
    "$$\n",
    "y - prediction\n",
    "$$\n",
    "\n",
    "In the code, we are going to use\n",
    "\n",
    "$$\n",
    "prediction - y\n",
    "$$\n",
    "\n",
    "as our loss is\n",
    "$$-\\sum_{b}\\sum_{i}{y_{b, i}\\log{(\\text{prediction}_{b, i}})}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix B - Adagrad (simplified version)\n",
    "\n",
    "Let $p_1, \\ldots, p_n$ be all parameters in our model (weights and biases).  \n",
    "For parameter $p_i$ we maintain an array $G_i$ (can be set to $0$ initially).\n",
    "Let $\\text{LOSS}$ be our loss without L2.  \n",
    "We update $G_i$ and $p_i$ each training step as follows:\n",
    "\n",
    "$$\n",
    "G_i = G_i +  \\left(\\frac{\\partial \\text{LOSS}}{\\partial p_i}\\right)^2\\\\\n",
    "p_i = p_i - \\frac{\\eta}{\\sqrt{\\left(G_i + \\epsilon\\right)}}\\frac{\\partial \\text{LOSS}}{\\partial p_i}\n",
    "$$\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "1mbRybTuEd5hfMgPq47jAy40aizNX03x8",
     "timestamp": 1665425459792
    },
    {
     "file_id": "1hs2ViNkY7vFE7l_PL7b-2XIN17cxbsyL",
     "timestamp": 1635823858600
    },
    {
     "file_id": "1t76la2tUWVLnEK7IKxdFZn_Y0be3xZud",
     "timestamp": 1635823610862
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "001c0f369ea04cdc87329ba70bc1da41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ab3ead1b8ee4a62b0e732e88a4b612b",
      "max": 1648877,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_457f5c77ef924c8d939c36fbdb525c3c",
      "value": 1648877
     }
    },
    "05a12b77a0344f168b0ce86235411193": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0887eb284cde433a93dc63af32cc9d9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7d1eed65ecca478498920df1c94a7ab1",
       "IPY_MODEL_4cc42c27336c4004b8636f12fc602c83",
       "IPY_MODEL_8e6fd5210a7348658773944836baa32d"
      ],
      "layout": "IPY_MODEL_358d8edb5961494884a519823853bbc1"
     }
    },
    "095b39beff514e799541c63dabc90507": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0eb41ae3f7c344728e7610e0ac2e85a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12c9382de5be4afa97c32ad53880f443": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1399a04e36fb44a0adb69561d892702b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36d9aac0f6324cc38e241ececa6a4983",
      "max": 28881,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6df1299ec9ef42098b23a7bd33291730",
      "value": 28881
     }
    },
    "179b581ba55d4666a7b598aa16d379c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_73d1c89e46e346978a24dfbdb3d107f9",
       "IPY_MODEL_001c0f369ea04cdc87329ba70bc1da41",
       "IPY_MODEL_6bc73c9a0f414c14ba1ba549122c6c9b"
      ],
      "layout": "IPY_MODEL_d89d4753c54a4106853af165e3580381"
     }
    },
    "1b9c5bf3d8ae457a96d50baf49906929": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12c9382de5be4afa97c32ad53880f443",
      "max": 4542,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_93588a37aca74159889b81666166d80a",
      "value": 4542
     }
    },
    "23a28a753e7c4234b064d55ba0d35eec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2b08ddda39424469a3248b0f152b9248": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "358d8edb5961494884a519823853bbc1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3644dba634e84dbcba3cefcfe8491a05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "36d9aac0f6324cc38e241ececa6a4983": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3aded8ec6c8c435db31880259a9c1d6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c475797b8c049bc900bdb82c9cee039": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5422f00593564627b8b1dbfe5c35375e",
       "IPY_MODEL_1399a04e36fb44a0adb69561d892702b",
       "IPY_MODEL_77df2c4f36ba43768f4b1afd46476f40"
      ],
      "layout": "IPY_MODEL_0eb41ae3f7c344728e7610e0ac2e85a0"
     }
    },
    "457f5c77ef924c8d939c36fbdb525c3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4cc42c27336c4004b8636f12fc602c83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5410d60a73fb4378bfcde8a43a5f75f5",
      "max": 9912422,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3644dba634e84dbcba3cefcfe8491a05",
      "value": 9912422
     }
    },
    "5410d60a73fb4378bfcde8a43a5f75f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5422f00593564627b8b1dbfe5c35375e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f676a65904b44a9baefab8c2a60e0eac",
      "placeholder": "​",
      "style": "IPY_MODEL_b1ef11936cde4ac8ac4cb6fd24c75ede",
      "value": ""
     }
    },
    "5a5c2ab34a0c4661b9c0611200e70e2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ab3ead1b8ee4a62b0e732e88a4b612b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c9484a4d1b84db0aa4b37f215af9857": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6a6f8922ea26440ab907305b2f73c184": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6bc73c9a0f414c14ba1ba549122c6c9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3aded8ec6c8c435db31880259a9c1d6f",
      "placeholder": "​",
      "style": "IPY_MODEL_6a6f8922ea26440ab907305b2f73c184",
      "value": " 1649664/? [00:00&lt;00:00, 20024693.20it/s]"
     }
    },
    "6df1299ec9ef42098b23a7bd33291730": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "73d1c89e46e346978a24dfbdb3d107f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0ff7bcdb6f244d3945dea309ffdef09",
      "placeholder": "​",
      "style": "IPY_MODEL_937845c378944bcfba102e57219117fc",
      "value": ""
     }
    },
    "77df2c4f36ba43768f4b1afd46476f40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fcda01da20f04bc0a9105f8b2baf9f2a",
      "placeholder": "​",
      "style": "IPY_MODEL_c34a23042e964b4395cc60915133b2ba",
      "value": " 29696/? [00:00&lt;00:00, 648756.19it/s]"
     }
    },
    "7d1eed65ecca478498920df1c94a7ab1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f78d21be3caf4c00b6d38d6a9f41acd0",
      "placeholder": "​",
      "style": "IPY_MODEL_a411ff8732a84c4ca7c4619a848c773a",
      "value": ""
     }
    },
    "7d6ec88d5f9b4b21b686f09fa415bd91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c5ef09e329c646ca98aebd21525f060e",
       "IPY_MODEL_1b9c5bf3d8ae457a96d50baf49906929",
       "IPY_MODEL_df3341a327524a1691aa7aca0006c490"
      ],
      "layout": "IPY_MODEL_2b08ddda39424469a3248b0f152b9248"
     }
    },
    "8e6fd5210a7348658773944836baa32d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05a12b77a0344f168b0ce86235411193",
      "placeholder": "​",
      "style": "IPY_MODEL_5c9484a4d1b84db0aa4b37f215af9857",
      "value": " 9913344/? [00:00&lt;00:00, 25975870.14it/s]"
     }
    },
    "93588a37aca74159889b81666166d80a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "937845c378944bcfba102e57219117fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0ff7bcdb6f244d3945dea309ffdef09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a411ff8732a84c4ca7c4619a848c773a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b1ef11936cde4ac8ac4cb6fd24c75ede": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c34a23042e964b4395cc60915133b2ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c5ef09e329c646ca98aebd21525f060e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e170ca7391a946b6a9febe117c16d87c",
      "placeholder": "​",
      "style": "IPY_MODEL_23a28a753e7c4234b064d55ba0d35eec",
      "value": ""
     }
    },
    "d89d4753c54a4106853af165e3580381": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df3341a327524a1691aa7aca0006c490": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a5c2ab34a0c4661b9c0611200e70e2b",
      "placeholder": "​",
      "style": "IPY_MODEL_095b39beff514e799541c63dabc90507",
      "value": " 5120/? [00:00&lt;00:00, 114088.88it/s]"
     }
    },
    "e170ca7391a946b6a9febe117c16d87c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f676a65904b44a9baefab8c2a60e0eac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f78d21be3caf4c00b6d38d6a9f41acd0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fcda01da20f04bc0a9105f8b2baf9f2a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
